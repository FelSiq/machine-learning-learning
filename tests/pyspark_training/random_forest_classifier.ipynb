{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "going-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.ml\n",
    "import pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifteen-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(\"local\", \"RF\")\n",
    "ss = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gothic-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ss.read.csv(\"data/PS_20174392719_1491204439457_log.csv\", inferSchema=True, header=True).limit(int(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "experimental-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greenhouse-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"isFlaggedFraud\", \"step\", \"nameDest\", \"nameOrig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dental-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df.randomSplit([0.9, 0.1], seed=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bearing-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c, dtype in df_train.dtypes if dtype == \"string\"]\n",
    "num_cols = list(set(df_train.columns) - set(cat_cols) - {\"isFraud\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "congressional-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type']\n",
      "['oldbalanceDest', 'newbalanceOrig', 'amount', 'oldbalanceOrg', 'newbalanceDest']\n"
     ]
    }
   ],
   "source": [
    "print(cat_cols)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "celtic-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pyspark.ml.Pipeline().setStages([\n",
    "    pyspark.ml.feature.VectorAssembler(inputCols=num_cols, outputCol=\"vec_feats_num\"),\n",
    "    pyspark.ml.feature.StandardScaler(inputCol=\"vec_feats_num\", outputCol=\"standardized\"),\n",
    "    pyspark.ml.feature.StringIndexer(inputCol=\"type\", outputCol=\"type_id\", handleInvalid=\"skip\"),\n",
    "    pyspark.ml.feature.OneHotEncoder(inputCol=\"type_id\", outputCol=\"type_ohe\"),\n",
    "    pyspark.ml.feature.VectorAssembler(inputCols=[\"type_ohe\", \"standardized\"], outputCol=\"features\"),\n",
    "])\n",
    "\n",
    "pipeline = pipeline.fit(df_train)\n",
    "\n",
    "X_train = pipeline.transform(df_train)\n",
    "X_test = pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "several-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyspark.ml.classification.RandomForestClassifier(\n",
    "    labelCol=\"isFraud\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=50,\n",
    ").fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rental-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "about-consultation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       rawPrediction|\n",
      "+--------------------+\n",
      "|[49.9794522652633...|\n",
      "|[49.9794522652633...|\n",
      "|[49.9342634155234...|\n",
      "|[49.9794522652633...|\n",
      "|[49.9794522652633...|\n",
      "|[49.9794522652633...|\n",
      "|[49.9385793550974...|\n",
      "|[49.9794522652633...|\n",
      "|[49.9381363649365...|\n",
      "|[49.9773127251739...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds.select(\"rawPrediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intended-typing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC : 0.990\n",
      "PR AUC  : 0.675\n"
     ]
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator(\n",
    "    labelCol=\"isFraud\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\")\n",
    "\n",
    "roc_auc = evaluator.evaluate(y_preds)\n",
    "print(f\"ROC AUC : {roc_auc:.3f}\")\n",
    "\n",
    "\n",
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator(\n",
    "    labelCol=\"isFraud\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderPR\")\n",
    "\n",
    "pr_auc = evaluator.evaluate(y_preds)\n",
    "print(f\"PR AUC  : {pr_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "particular-bobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC  : 0.998\n"
     ]
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.MulticlassClassificationEvaluator(\n",
    "    labelCol=\"isFraud\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\",\n",
    ")\n",
    "\n",
    "f1 = evaluator.evaluate(y_preds)\n",
    "print(f\"PR AUC  : {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
