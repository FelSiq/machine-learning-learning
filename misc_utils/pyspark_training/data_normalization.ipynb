{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brilliant-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql\n",
    "import numpy as np\n",
    "import pyspark.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "removable-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "working-tsunami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://felsiq.box:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4f40a09790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iraqi-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.read.csv(\"data/PS_20174392719_1491204439457_log.csv\", inferSchema=True, header=True).limit(int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "varied-coalition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- isFlaggedFraud: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "postal-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ranging-swing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hollywood-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop seemingly unnecessary columns\n",
    "df = df.drop(\"nameOrig\", \"isFlaggedFraud\", \"nameDest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protecting-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df.randomSplit([0.9, 0.1], seed=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nuclear-kenya",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899894"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "gentle-testimony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|isFraud| count|\n",
      "+-------+------+\n",
      "|      0|899418|\n",
      "|      1|   476|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.select(\"isFraud\").groupBy(\"isFraud\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-acrobat",
   "metadata": {},
   "source": [
    "## Find out which columns are numerical and which ones are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cross-confusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type']\n",
      "['oldbalanceOrg', 'amount', 'newbalanceDest', 'newbalanceOrig', 'oldbalanceDest', 'step']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [col for col, dtype in df_train.dtypes if dtype == \"string\"]\n",
    "num_cols = list(set(df_train.columns) - set(cat_cols) - {\"isFraud\", \"isFlaggedFraud\"})\n",
    "\n",
    "print(cat_cols)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-nicholas",
   "metadata": {},
   "source": [
    "## Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rising-white",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.pipeline.Pipeline'>\n",
      "<class 'pyspark.ml.pipeline.PipelineModel'>\n"
     ]
    }
   ],
   "source": [
    "pipeline_num = pyspark.ml.Pipeline().setStages([\n",
    "    pyspark.ml.feature.VectorAssembler(inputCols=num_cols, outputCol=\"vec_feats_num\"),\n",
    "    pyspark.ml.feature.StandardScaler(inputCol=\"vec_feats_num\", outputCol=\"standardized\")\n",
    "])\n",
    "\n",
    "print(type(pipeline_num))\n",
    "pipeline_num = pipeline_num.fit(df_train)\n",
    "print(type(pipeline_num))\n",
    "\n",
    "df_train_std = pipeline_num.transform(df_train)\n",
    "df_test_std = pipeline_num.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-victor",
   "metadata": {},
   "source": [
    "## Categorical features investigation and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "viral-hollywood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{c: df_train_std.select(c).distinct().count() for c in cat_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "soviet-resistance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|    type| count|\n",
      "+--------+------+\n",
      "| CASH_IN|196881|\n",
      "|CASH_OUT|326287|\n",
      "|   DEBIT|  5792|\n",
      "| PAYMENT|296681|\n",
      "|TRANSFER| 74253|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_std.groupBy(\"type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "gothic-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_indexers = [\n",
    "    pyspark.ml.feature.StringIndexer(inputCol=c, outputCol=f\"{c}_si\", handleInvalid=\"skip\")\n",
    "    for c in cat_cols\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "political-cathedral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.pipeline.Pipeline'>\n",
      "<class 'pyspark.ml.pipeline.PipelineModel'>\n"
     ]
    }
   ],
   "source": [
    "pipeline_cat = pyspark.ml.Pipeline().setStages([\n",
    "    *string_indexers,\n",
    "    pyspark.ml.feature.OneHotEncoder(\n",
    "        inputCols=[f\"{c}_si\" for c in cat_cols],\n",
    "        outputCols=[f\"{c}_ohe\" for c in cat_cols],\n",
    "    )\n",
    "])\n",
    "\n",
    "print(type(pipeline_cat))\n",
    "pipeline_cat = pipeline_cat.fit(df_train)\n",
    "print(type(pipeline_cat))\n",
    "\n",
    "df_train_std = pipeline_cat.transform(df_train_std)\n",
    "df_test_std = pipeline_cat.transform(df_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "perceived-hughes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------+-------------+--------------+--------------+--------------+-------+--------------------+--------------------+-------+-------------+\n",
      "|step|   type|amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|       vec_feats_num|        standardized|type_si|     type_ohe|\n",
      "+----+-------+------+-------------+--------------+--------------+--------------+-------+--------------------+--------------------+-------+-------------+\n",
      "|   1|CASH_IN|270.78|   4184966.65|    4185237.43|        3019.0|           0.0|      0|[4184966.65,270.7...|[1.40334656937633...|    2.0|(4,[2],[1.0])|\n",
      "|   1|CASH_IN|484.57|   5422437.76|    5422922.33|    5638778.53|    5579568.65|      0|[5422437.76,484.5...|[1.81830826015129...|    2.0|(4,[2],[1.0])|\n",
      "|   1|CASH_IN|783.31|   8150331.93|    8151115.24|       2013.12|       1229.81|      0|[8150331.93,783.3...|[2.73305412200689...|    2.0|(4,[2],[1.0])|\n",
      "|   1|CASH_IN|863.08|   9290756.54|    9291619.62|       5577.88|        4714.8|      0|[9290756.54,863.0...|[3.11547317045399...|    2.0|(4,[2],[1.0])|\n",
      "|   1|CASH_IN|911.76|   1335635.48|    1336547.24|       48321.6|      47409.85|      0|[1335635.48,911.7...|[0.44787918890472...|    2.0|(4,[2],[1.0])|\n",
      "+----+-------+------+-------------+--------------+--------------+--------------+-------+--------------------+--------------------+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_std.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "timely-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------+-------------+--------------+--------------+--------------+-------+--------------------+--------------------+-------+-------------+\n",
      "|step|   type|  amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|       vec_feats_num|        standardized|type_si|     type_ohe|\n",
      "+----+-------+--------+-------------+--------------+--------------+--------------+-------+--------------------+--------------------+-------+-------------+\n",
      "|   1|CASH_IN|27070.11|    346803.59|      373873.7|       70595.0|     122750.49|      0|[346803.59,27070....|[0.11629378892993...|    2.0|(4,[2],[1.0])|\n",
      "|   1|CASH_IN|30811.56|   7243810.89|    7274622.45|      152178.0|     651524.92|      0|[7243810.89,30811...|[2.42907005285034...|    2.0|(4,[2],[1.0])|\n",
      "|   1|CASH_IN|31646.31|   5847973.23|    5879619.54|      58072.44|       66575.5|      0|[5847973.23,31646...|[1.96100324243328...|    2.0|(4,[2],[1.0])|\n",
      "|   1|CASH_IN|32726.88|   1640596.99|    1673323.87|     102483.74|      69756.86|      0|[1640596.99,32726...|[0.55014205612502...|    2.0|(4,[2],[1.0])|\n",
      "|   1|CASH_IN|34784.78|   1245553.78|    1280338.56|     812330.95|    1186556.81|      0|[1245553.78,34784...|[0.41767205579445...|    2.0|(4,[2],[1.0])|\n",
      "+----+-------+--------+-------------+--------------+--------------+--------------+-------+--------------------+--------------------+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_std.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "distributed-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "va = pyspark.ml.feature.VectorAssembler(inputCols=[\"standardized\", \"type_ohe\"], outputCol=\"vec_feats_total\")\n",
    "df_train_aux = va.transform(df_train_std)\n",
    "\n",
    "# This is a requirement of Spark (a vector column named 'features' and a double column named 'label').\n",
    "data = df_train_aux.select(\n",
    "    pyspark.sql.functions.col(\"vec_feats_total\").alias(\"features\"),\n",
    "    pyspark.sql.functions.col(\"isFraud\").alias(\"label\"),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "accompanied-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                    |label|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|[1.403346569376335,0.0010435331993796247,0.0,1.3862883161119874,0.0013116646729908526,0.07904243517400436,0.0,0.0,1.0,0.0]                  |0    |\n",
      "|[1.818308260151296,0.001867438076753766,2.301952399993384,1.7962502703847307,2.4498796278967507,0.07904243517400436,0.0,0.0,1.0,0.0]        |0    |\n",
      "|[2.733054122006899,0.003018723651695302,5.073804551245845E-4,2.699917509935478,8.746400750219758E-4,0.07904243517400436,0.0,0.0,1.0,0.0]    |0    |\n",
      "|[3.1154731704539977,0.003326141641629982,0.0019451763848248034,3.0776900790937693,0.0024234210487519767,0.07904243517400436,0.0,0.0,1.0,0.0]|0    |\n",
      "|[0.44787918890472267,0.0035137448477227514,0.019559794822280097,0.4427084134970389,0.02099428143835534,0.07904243517400436,0.0,0.0,1.0,0.0] |0    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "upper-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyspark.ml.classification.LogisticRegression().fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "related-methodology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852501267813298"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "false-workplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|            recall|           precision|\n",
      "+------------------+--------------------+\n",
      "|               0.0|  0.5493333333333333|\n",
      "|0.4327731092436975|  0.5493333333333333|\n",
      "|0.5735294117647058| 0.37092391304347827|\n",
      "|0.6491596638655462| 0.28167730173199634|\n",
      "|0.6764705882352942| 0.22085048010973937|\n",
      "|0.6953781512605042| 0.18196811434854315|\n",
      "|0.6974789915966386| 0.15229357798165138|\n",
      "|0.7121848739495799|  0.1334120425029516|\n",
      "|0.7226890756302521| 0.11853893866299105|\n",
      "|0.7247899159663865|  0.1057309224639902|\n",
      "|0.7310924369747899| 0.09602649006622517|\n",
      "|0.7373949579831933| 0.08808030112923464|\n",
      "|0.7457983193277311| 0.08168430740911183|\n",
      "|0.7478991596638656| 0.07563203739111961|\n",
      "|0.7605042016806722| 0.07142857142857142|\n",
      "|0.7710084033613446| 0.06759992632160619|\n",
      "|0.7878151260504201| 0.06476683937823834|\n",
      "|0.8046218487394958|0.062266298162900344|\n",
      "|0.8130252100840336| 0.05942874692874693|\n",
      "|0.8340336134453782|  0.0577622581114506|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.summary.pr.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
